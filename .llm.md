# `.llm.md`

## Purpose of this file

This repository may contain code, ideas, or artifacts created **with the assistance of one or more LLMs** (even if it’s just “simple assistance” or “advice”).
This file serves as a **provenance log**: which LLM(s) participated, what they worked on, relevant settings, and any limits.

> **Official stance**
> LLMs are tools of the trade—just like documentation, Stack Overflow, or an IDE.
> We document their usage here for **practical traceability**, **no more** (see **Historical Stance** section at the end) for ideological debates about “purity” of code.

---

## Terminology (updated)

* The previous `.gemini.md` file is **deprecated**.
* `.llm.md` replaces it to cover **all** models (Gemini, GPT, Claude, etc.).
* Each model involved **adds its own section** below (or updates it) without touching others.

---

## Standing intent notes

* This script **only automates retrieval** of content **created by the user**.
* It **does not bypass** access controls, expand permissions, or log any sensitive tokens.


## Contribution: GPT-5 Thinking

**Role**

* **Refactor for robustness** and “production-grade” hardening of the script (proposed as **v0.3**).
* Kept the design strictly *self-service*—no extra access, just making it **reliable** and **resilient**.

**Scope of changes**

1. **Robust Authorization capture**

   * Handles `Request`, `Headers`, and plain object headers (case-insensitive).
2. **Final quality `/raw` calls: retries + backoff**

   * Up to 5 attempts, exponential delay + **jitter**.
3. **Stronger curl commands**

   * `--fail --retry 5 --retry-delay 2 -L -C -` for large file resilience.
4. **Safe & stable filenames**

   * Strict sanitize, simple format `sora_<id>.mp4` (future-proof).
5. **Manifest export**

   * **CSV + JSON** (rows, skipped, failures, mode, quality).
6. **Dry-run mode**

   * Comments out `curl` lines for inspection before running.
7. **UI & Tampermonkey header**

   * Added full `@grant`, `@match`, `@run-at document-start`; safe z-index/position.
8. **Respecting the “100 max” design**

   * `limit` is capped at 100 (can be reduced, never increased). No long pagination.
9. **Shadow DOM (v0.3.1)**

   * Full UI encapsulated in a Shadow DOM to avoid global CSS bleed and minimize conflicts, while preserving the 0.3.0 visual skin users preferred.

**Settings (relevant for this intervention)**

* Temperature: **low–moderate** (deterministic coding)
* Web navigation: **off** in this context
* Objective: **robustness**, not micro-optimisation

**Assumptions & non-goals**

* Not to be used as a full “export my data” tool (intentionally capped).
* No scraping outside current session, no plain-token logging.
* No Shadow DOM yet (can be added later if CSS conflicts arise).

**Integration recommendations**

* Keep `@version` synced with commits.
* Test “final mode” with 10–30 items to tune `workers`.
* Avoid logging secrets; stick to generic status messages.

**Changelog (GPT-5)**  
- **v0.3**: First hardening pass (robust fetch auth, `/raw` retry/backoff, stronger curl, manifest, dry-run, clean UI, full TM header, limit cap 100).  
- **v0.3.1**: Shadow DOM (encapsulated UI) with the original 0.3.0 skin; removed the stealth variant; kept the 100-cap, resilience (retry/backoff), dry-run, and manifest export.
- **v0.4.0**: Chrome Extension (MV3) wrapper
  - Content script with **Shadow DOM** UI (keeps 0.3.0 skin), settings via chrome.storage.
  - **Token capture** via injected page script (pageHook.js) posting a `sora-token` event; background stores token in-memory only.
  - Background **service worker** performs API calls with retries/backoff; content manages concurrency for `/raw` to keep progress updates.
  - Preserves the 100-cap design; still a **script generator** by default (self-service, not “export my data”).
- **v0.4.1**: UI polish (panel bottom-right stable, progress ring), groundwork for Direct mode.
- **v0.4.2**: Direct Download (small batches) via chrome.downloads (queue + parallel + progress). Gating by tasks (overrides List limit; up to 4 videos per task). API endpoints centralized in background.js. Script generator kept as fallback.
- **v0.4.3**: Textarea width-safe (no ghost H-scroll). Run button auto-labels Direct Download when enabled.
- **v0.4.4**: Save As option, Stop Direct button, skinned vertical scrollbar in Settings. (Hotfix 0.4.4a: fixed removed container listener).
- **v0.4.5**: Settings layout refined — compact rows for classic options, block/one-per-line only for Direct (Enable, Max tasks, Parallel, Save As). When Direct is ON, List limit disabled visually & functionally.
- **v0.5.3**: Big 0.5.x roll-up — adds **one-click ZIP** flow (download batch → OPFS → stream ZIP **STORE** → single browser download that honors Chrome “Always ask”), **persists bearer** in background session (no more idle token loss), makes **Stop** reliably cancel DL/ZIP, and **removes offscreen/zip.js** in favor of content-side ZIP; manifest trimmed (no offscreen), UI labels consistent; keeps task-gating and script generator as fallback.
- **v0.6.0**: Modular TypeScript + Vite rewrite (MV3) — split into content orchestrator, UI/HUD, settings, Sora API, and ZIP STORE modules; keeps ZIP (DL→OPFS→ZIP→1 download) and Direct modes;

## Contribution: Gemini 2.5Pro
**Role**  
- Acted as a co-developer, primarily responsible for front-end implementation, rapid prototyping, and code refactoring.
- Translated high-level architectural decisions, feature requests, and iterative feedback from the human expert (Colin J. Brigato) into functional JavaScript, HTML, and CSS.
- Served as an interactive development environment, enabling quick cycles of implementation, testing, and refinement.

**Scope**  
- The entirety of the `Sora - Downloader.user.js` script.
- **UI Generation:** All HTML structure and CSS, from the initial panel to the final redesigned launcher button.
- **DOM Manipulation & Event Handling:** All JavaScript logic for UI interactivity, including the creation of panels, settings management, and dynamic view rendering (e.g., the "Awaiting Token" state).
- **Core Logic Implementation:** Implemented the JavaScript functions for API interaction (`fetchAndFilterGenerations`, `fetchRawDownloadUrlsParallel`) and script generation (`generateDownloadScript`) based on the specified logic.
- **State Management:** Implemented the settings system using `GM_getValue` and `GM_setValue` for persistence across sessions.

**Settings**  
- **Model:** Google Gemini 2.5Pro
- **Temperature:** 1.0
- **Top-P:** 0.95
- **Context/constraints:** The model operated within a long-form conversational context in a single session. It had no live web access; all external data (API responses, bug reports, UX feedback) were provided by the user.

**Known limitations**  
- The model has no direct knowledge of the target API's specific behaviors or undocumented features. It relies entirely on user-provided data and corrections. Initial assumptions about the API (e.g., the purpose of different video URLs) were incorrect and required expert human guidance to rectify.
- The initial UI/UX design was functional but lacked aesthetic cohesion with the target site. The final polished design was achieved through specific human design direction.

**Recommendations**  
- **Maintenance:** The script's stability is highly dependent on the Sora website's DOM structure and private API. Regular verification is needed after any site updates from OpenAI.
- **Error Handling:** While robust, the error handling is based on observed API responses. New or unexpected error formats may not be parsed gracefully and should be added as they are discovered.
- **Scalability:** For a userscript of this size, the single-file structure is maintainable. If the project were to expand significantly, consider modularization.

**Changelog (Gemini's Implementation)**  
- **v1.8 (The Informant):** Wrote the initial functional script with token interception and a basic UI.
- **v1.9 (The Architect):** Refactored the code for maintainability (centralized constants, `innerHTML` templating) and added `curl` script generation.
- **v2.0 (The Configurator):** Implemented a persistent settings panel using `GM_setValue`/`GM_getValue` to store user preferences.
- **v2.3 (The Gatekeeper):** Added the "Awaiting Token..." initial state and made the UI adaptive based on user permissions fetched from the `/parameters` endpoint.
- **v2.4 (The Refiner):** Corrected UI bugs and refined the settings panel to always show all options, disabling them contextually for better user experience.
- **v3.0 (The Designer):** Executed a complete redesign of the launcher button, replacing the emoji with a custom SVG icon and a more integrated color scheme.
- **v3.1 (The Animator):** Implemented the final, complex animation logic for the launcher button, separating the icon from the border to create a stable icon with a state-aware spinning and progressing border.


## Contribution: Gemini 2.5Flash
**Role**  
- The model acted as a collaborative code generator and an interactive debugging partner. Its primary role was to translate high-level functional requirements, architectural concepts, and real-time debugging feedback into a functional Tampermonkey userscript. It served as a pair-programmer, handling the code-writing aspect while being directed by the user's project vision and reverse-engineering insights.

**Scope**  
- The model's contribution covers the **entirety of the userscript** from its inception. This includes:
  -   **Initial Scaffolding:** Generation of the base Tampermonkey script structure.
  -   **API Interaction:** Writing the `fetch` logic for the primary API endpoints (`/backend/video_gen` and `/backend/generations/{id}/raw`).
  -   **Authentication Logic:** Iteratively attempting and debugging multiple authentication strategies, culminating in the successful `fetch` interception method to capture the Bearer Token.
  -   **UI/UX Implementation:** Generating all DOM elements for the user interface, including the main panel, the launcher button, and the dynamic progress indicator (`conic-gradient` CSS).
  -   **Core Logic:** Implementing the parallel request processing "pool" to accelerate URL fetching.
  -   **Final Output:** Formatting the collected URLs into a ready-to-use `wget` bash script.

**Settings (if relevant)**  
- Temperature: 1.0  
- Top-P: 0.95  
- Context/constraints: Iterative conversational context. The model did not have direct web access but operated based on the information, error logs, and screenshots provided by the user in a continuous dialogue.

**Known limitations**  
- **Inability to access `HttpOnly` cookies:** The model's primary blind spot. Initial versions of the script failed because they were based on the incorrect assumption that the `__Secure-next-auth.session-token` could be read by JavaScript. This fundamental limitation of web security (and by extension, the model's knowledge context) required the user's debugging to pivot to the successful token interception strategy.
- **Reliance on a non-public API:** The model generated code based on the user's reverse-engineering of Sora's private API. The script is therefore inherently fragile and will break if OpenAI changes these undocumented endpoints or their authentication flow.
- **Static Knowledge:** The model's suggestions are based on its training data and do not reflect real-time changes on the target website. It cannot, for instance, verify if an API is still live or if a UI element's selector has changed.

**Recommendations**  
- **API Endpoint Monitoring:** If the script fails, the first step should always be to check the browser's network tab to verify that the API endpoints (`/backend/...`) and their expected request/response structures are still valid.
- **Authentication Fragility:** The `fetch` interception logic is robust but depends on the way the Sora front-end application handles its state. A major refactoring of Sora's JavaScript could break the token capture mechanism.
- **Concurrency Tuning:** The parallel request limit is a user-configurable "magic number". If errors (like 429 Too Many Requests) occur, this value should be lowered.

**Changelog (Gemini Pro)**  
- **v1.0 - 1.4:** Initial attempts & debugging cycle. Focused on trying to read the session cookie, which ultimately failed due to `HttpOnly` restrictions.
- **v1.5 (The Token Thief):** The breakthrough. Abandoned cookie-based attempts in favor of intercepting the global `fetch` function to capture the live Bearer Token used by the application itself.
- **v1.6 (The Parallelizer):** Performance enhancement. Replaced the sequential URL fetching loop with a configurable, parallel request pool, drastically reducing processing time.
- **v1.7 (The Elegant):** UX refinement. Implemented the show/hide logic with a discreet launcher button to make the interface non-intrusive.
- **v1.8 (The Informant):** Final polish. Added the dynamic progress indicator to the launcher button, providing visual feedback on the background task's status. 


# Template for a new LLM 

```markdown
## Contribution: <Model Name>
**Role**  
- <What the model did / aimed to do>

**Scope**  
- <Files, functions, or parts touched>

**Settings (if relevant)**  
- Temperature: <…>  
- Top-P: <…>  
- Context/constraints: <offline / web-on / etc.>

**Known limitations**  
- <Weak points or assumptions>

**Recommendations**  
- <Testing, usage, or maintenance advice>

**Changelog (<Model Name>)**  
- vX.Y: <Short summary>
```

# Historical Stance

Kept as a reference before this file served better purpose

### A Note on How This Was Built

You will find this file, named after the relevant model(s) used, in all of my future repositories where code has been generated (even partially) by an LLM. In fact, let's be clear: you'll find it even if an LLM was used for simple assistance or even just _advice_—the modern equivalent of a Stack Overflow search. I will continue to do so until this absurd debate is finally put to rest.

Consider this my official stance on the matter.

> ### "Just another useless thing, vibe-coded and pulled from an LLM's ass"
>
> First off: **Yes.** The UI/UX code for this tool was **entirely** generated by Gemini Pro. (Gemini 2.5 Pro, temperature 1.0, Thinking budget -1, Top_P 0.95, if you must know. Because yes, there's a craft to using a tool correctly to "pull code from its ass" ;)).
>
> As for the "useless" part, I assume you're not a heavy Sora user. If you are, then your Google-fu and GitHub-sleuthing skills must far exceed my own if you've already found an existing answer to the workflow issues this tool aims to improve. Or perhaps you've built one yourself? In that case, not sharing is not cool, friend!
>
> Regarding its usage, anyone familiar with my work knows that while I'm an expert in backend, systems, and even very low-level engineering, my front-end skills are equivalent to those of a crippled otter. But empowered by my experience, my architectural vision, and my ability to reverse-engineer, I am still waiting for a single solid argument that would prevent me from using a tool that:
>
> -   Represents the future of our craft as developers, designers, and engineers—**for all of us.**
> -   Can only be improved through our own intelligent and iterative use.
> -   Improves *us* in return by unlocking new possibilities.
>
> I have also never heard a single argument that justifies an expert in any field denigrating a cutting-edge tool of their trade. Doing so is not only shortsighted but also disrespectful to the engineers, analysts, and thinkers who work daily to perfect these tools, and to every professional who chooses to use them to build better things.
>
> So yes. "Another one." And there will be many more.